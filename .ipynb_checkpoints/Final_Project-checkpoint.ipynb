{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f648c497-bc00-400b-bfa3-43d1541c5ed4",
   "metadata": {},
   "source": [
    "# Spring 2025 Data Science Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3f488b-ab7b-4260-9d6f-bc12ad14ed99",
   "metadata": {},
   "source": [
    "By: Katherine, Sayee, Yiran, Asmita\n",
    "\n",
    "## Contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71155651-e758-4d1c-974d-d622c37ee835",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb14fbf-03ee-4d0c-befa-fcf316966f0e",
   "metadata": {},
   "source": [
    "## Data Curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "049f1b12-ea4c-47ab-9020-09dc0ba43ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
       "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
       "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
       "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
       "       'total_amount', 'congestion_surcharge', 'Airport_fee'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#importing dataset from file\n",
    "df = pd.read_parquet('yellow_tripdata_2024-01.parquet')\n",
    "\n",
    "#cleaning dataset by removing entriees with missing data or inappropiate dates\n",
    "df = df.dropna()\n",
    "date = pd.Timestamp(2024, 1, 1)\n",
    "df = df[df['tpep_pickup_datetime'] >= date]\n",
    "date = pd.Timestamp(2024, 2, 1)\n",
    "df = df[df['tpep_pickup_datetime'] < date]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78a8d2d-d0ce-488a-a8be-d2791559404c",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "123a7cc2-9fd6-4cf8-b319-c6d3d4d1fa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#port the stuff from the other document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e20246-f878-4a11-b06f-ee4ef8387bd8",
   "metadata": {},
   "source": [
    "## Primary Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1931efd-a3b1-48a3-93a4-a77805be3a72",
   "metadata": {},
   "source": [
    "### An Evaluation of Factors Impacting Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0396700-1a84-400f-a7e8-4aa515919cf2",
   "metadata": {},
   "source": [
    "Here we are applying some filtering to ensure the exclusion of problematic data like significant outliers in the trip distance and negative fares. We are the creating a column with a calculation of the tip as a percentage of the total fare. In this section we are evaluating a few models for predicting this tip percentage based on a few other features. For the purpose of not overtaxing my computer and waiting 50 hours for a result, we are only using a sample of the whole data set. This is because I would like to look at how accurate Random Forest is at fitting the data, but I simply cannot get it to run on the whole dataset of over 2000000 points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f5f1729d-eec5-4d93-917b-2158e9a8d6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = df.dropna()\n",
    "date = pd.Timestamp(2024, 1, 1)\n",
    "df = df[df['tpep_pickup_datetime'] >= date]\n",
    "date = pd.Timestamp(2024, 2, 1)\n",
    "df = df[df['tpep_pickup_datetime'] < date]\n",
    "\n",
    "dff = df[df['trip_distance'] <= 800]\n",
    "dff = dff[dff['tip_amount'] >= 0]\n",
    "dff = dff[dff['total_amount'] > 0]\n",
    "dff['tip_percent'] = dff['tip_amount']/dff['total_amount']\n",
    "dff.dropna()\n",
    "dft = dff.sample(10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c4d9ab-60dc-47d0-b737-951a71b4dfe9",
   "metadata": {},
   "source": [
    "In this section we are selecting the features we wish to evaluate and creating a training set. We are also scaling the data to ensure that none are unduely weighted in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bffbb70b-eb1c-4c02-af05-92a0c07ee1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "\n",
    "features = ['trip_distance', 'total_amount',\n",
    "       'tolls_amount', 'PULocationID']\n",
    "X = dft[features]\n",
    "Y = dft['tip_percent']\n",
    "\n",
    "random_state = 42\n",
    "test_size = 0.5\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size= test_size, random_state=random_state)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "scaler = preprocessing.StandardScaler().fit(X_test)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3ebdbe-1699-449e-9128-d24189db57b2",
   "metadata": {},
   "source": [
    "Here we are evaluating the accuracy of three models: K nearest neighbors, Decision Tree, and Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a6da76f8-c0a8-416a-9fa1-561f9780d5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN: 0.183\n",
      "Accuracy of Decision Tree: -0.402\n",
      "Accuracy of Random Forest: 0.235\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"KNN\": KNeighborsRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "         }\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    np.random.seed(42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    np.random.seed(42)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = model.score(X_test_scaled, y_test)\n",
    "    print(f\"Accuracy of {model_name}: {accuracy:.3f}\") # Your accuracy table header here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80cec1f-b1db-4662-ad43-0f6d9f68adf2",
   "metadata": {},
   "source": [
    "From these results we see that Random Forest has the highest accuracy of the tested models. K nearest neighbors is close behind while Decision Tree actually has negative accuracy. Unfortunately Random Forest is not very efficient on the particular machines we are using so we will proceed with K nearest neighbors. \n",
    "\n",
    "\n",
    "We sill now fit the selected model on the entirety of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9ae4c378-2e4e-418d-b67a-dfcbe0315b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dff[features]\n",
    "Y = dff['tip_percent']\n",
    "\n",
    "random_state = 42\n",
    "test_size = 0.5\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size= test_size, random_state=random_state)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "scaler = preprocessing.StandardScaler().fit(X_test)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "fit = knn.fit(X_train_scaled, y_train)\n",
    "y_pred = knn.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811079ef-c6f2-452e-892e-c2c69a2a632c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "result = permutation_importance(fit, X_train_scaled, y_train, n_repeats=10,\n",
    "                                random_state=0)\n",
    "importance = result.importances\n",
    "print(result.importances)\n",
    "feature_importance_df = pd.DataFrame({'feature':X_train.columns, 'importance':importance})\n",
    "print(feature_importance_df.sort_values('importance', ascending = False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec21842c-5c2a-44ab-bebb-8512dedfe391",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(feature_importance_df[['importance']], labels=feature_importance_df[['feature']], colors=colors, shadow=True)\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.title('Effect of various features on tip percentage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ed3669-efe1-4e64-a388-4b6e4e7b0b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_importances_idx = importance.importances_mean.argsort()\n",
    "importances = pd.DataFrame(\n",
    "    result.importances[sorted_importances_idx].T,\n",
    "    columns=X.columns[sorted_importances_idx],\n",
    ")\n",
    "ax = importances.plot.box(vert=False, whis=10)\n",
    "ax.set_title(\"Permutation Importances (test set)\")\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "ax.figure.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa86b9b-46b8-42b0-9bf8-266e0ea188d1",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f4d927-6248-4ebb-9623-eb261911a01a",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927792db-6fc7-472f-a0fb-cbca41b5d9b9",
   "metadata": {},
   "source": [
    "Stuff written so nicely..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd9bcc1-0c9b-45c3-b8df-b4240a7594eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea0cecd-1e71-494e-8874-d527b7c3259a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
