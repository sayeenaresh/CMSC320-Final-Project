{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f648c497-bc00-400b-bfa3-43d1541c5ed4",
   "metadata": {},
   "source": [
    "# Spring 2025 Data Science Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3f488b-ab7b-4260-9d6f-bc12ad14ed99",
   "metadata": {},
   "source": [
    "By: Katherine, Sayee, Yiran, Asmita\n",
    "\n",
    "## Contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71155651-e758-4d1c-974d-d622c37ee835",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb14fbf-03ee-4d0c-befa-fcf316966f0e",
   "metadata": {},
   "source": [
    "## Data Curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "049f1b12-ea4c-47ab-9020-09dc0ba43ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
       "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
       "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
       "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
       "       'total_amount', 'congestion_surcharge', 'Airport_fee'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#importing dataset from file\n",
    "df = pd.read_parquet('yellow_tripdata_2024-01.parquet')\n",
    "\n",
    "#cleaning dataset by removing entriees with missing data or inappropiate dates\n",
    "df = df.dropna()\n",
    "date = pd.Timestamp(2024, 1, 1)\n",
    "df = df[df['tpep_pickup_datetime'] >= date]\n",
    "date = pd.Timestamp(2024, 2, 1)\n",
    "df = df[df['tpep_pickup_datetime'] < date]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78a8d2d-d0ce-488a-a8be-d2791559404c",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "123a7cc2-9fd6-4cf8-b319-c6d3d4d1fa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#port the stuff from the other document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e20246-f878-4a11-b06f-ee4ef8387bd8",
   "metadata": {},
   "source": [
    "## Primary Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1931efd-a3b1-48a3-93a4-a77805be3a72",
   "metadata": {},
   "source": [
    "### An Evaluation of Factors Impacting Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0396700-1a84-400f-a7e8-4aa515919cf2",
   "metadata": {},
   "source": [
    "Here we are applying some filtering to ensure the exclusion of problematic data like significant outliers in the trip distance and negative fares. We are the creating a column with a calculation of the tip as a percentage of the total fare. In this section we are evaluating a few models for predicting this tip percentage based on a few other features. For the purpose of not overtaxing my computer and waiting 50 hours for a result, we are only using a sample of the whole data set. This is because I would like to look at how accurate Random Forest is at fitting the data, but I simply cannot get it to run on the whole dataset of over 2000000 points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f5f1729d-eec5-4d93-917b-2158e9a8d6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df = df.dropna()\n",
    "date = pd.Timestamp(2024, 1, 1)\n",
    "df = df[df['tpep_pickup_datetime'] >= date]\n",
    "date = pd.Timestamp(2024, 2, 1)\n",
    "df = df[df['tpep_pickup_datetime'] < date]\n",
    "\n",
    "dff = df[df['trip_distance'] <= 800]\n",
    "dff = dff[dff['tip_amount'] >= 0]\n",
    "dff = dff[dff['total_amount'] > 0]\n",
    "dff['tip_percent'] = dff['tip_amount']/dff['total_amount']\n",
    "dff.dropna()\n",
    "dft = dff.sample(10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c4d9ab-60dc-47d0-b737-951a71b4dfe9",
   "metadata": {},
   "source": [
    "In this section we are selecting the features we wish to evaluate and creating a training set. We are also scaling the data to ensure that none are unduely weighted in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bffbb70b-eb1c-4c02-af05-92a0c07ee1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "\n",
    "features = ['trip_distance', 'total_amount',\n",
    "       'tolls_amount', 'PULocationID']\n",
    "X = dft[features]\n",
    "Y = dft['tip_percent']\n",
    "\n",
    "random_state = 42\n",
    "test_size = 0.5\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size= test_size, random_state=random_state)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "scaler = preprocessing.StandardScaler().fit(X_test)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3ebdbe-1699-449e-9128-d24189db57b2",
   "metadata": {},
   "source": [
    "Here we are evaluating the accuracy of three models: K nearest neighbors, Decision Tree, and Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a6da76f8-c0a8-416a-9fa1-561f9780d5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN: 0.183\n",
      "Accuracy of Decision Tree: -0.402\n",
      "Accuracy of Random Forest: 0.235\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"KNN\": KNeighborsRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "         }\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    np.random.seed(42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    np.random.seed(42)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = model.score(X_test_scaled, y_test)\n",
    "    print(f\"Accuracy of {model_name}: {accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80cec1f-b1db-4662-ad43-0f6d9f68adf2",
   "metadata": {},
   "source": [
    "From these results we see that Random Forest has the highest accuracy of the tested models. K nearest neighbors is close behind while Decision Tree actually has negative accuracy. Unfortunately Random Forest is not very efficient on the particular machines we are using so we will proceed with K nearest neighbors. \n",
    "\n",
    "\n",
    "We sill now fit the selected model on the entirety of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9ae4c378-2e4e-418d-b67a-dfcbe0315b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dff[features]\n",
    "Y = dff['tip_percent']\n",
    "\n",
    "random_state = 42\n",
    "test_size = 0.5\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size= test_size, random_state=random_state)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "scaler = preprocessing.StandardScaler().fit(X_test)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "fit = knn.fit(X_train_scaled, y_train)\n",
    "y_pred = knn.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "811079ef-c6f2-452e-892e-c2c69a2a632c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[165], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minspection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m permutation_importance\n\u001b[1;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mpermutation_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m importance \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mimportances\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mimportances)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\inspection\\_permutation_importance.py:287\u001b[0m, in \u001b[0;36mpermutation_importance\u001b[1;34m(estimator, X, y, scoring, n_repeats, n_jobs, random_state, sample_weight, max_samples)\u001b[0m\n\u001b[0;32m    284\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m    285\u001b[0m baseline_score \u001b[38;5;241m=\u001b[39m _weights_scorer(scorer, estimator, X, y, sample_weight)\n\u001b[1;32m--> 287\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_calculate_permutation_scores\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(baseline_score, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    304\u001b[0m         name: _create_importances_bunch(\n\u001b[0;32m    305\u001b[0m             baseline_score[name],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m baseline_score\n\u001b[0;32m    310\u001b[0m     }\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "result = permutation_importance(fit, X_train_scaled, y_train, n_repeats=3, n_jobs = 3,\n",
    "                                random_state=0)\n",
    "importance = result.importances\n",
    "print(result.importances)\n",
    "feature_importance_df = pd.DataFrame({'feature':X_train.columns, 'importance':importance})\n",
    "print(feature_importance_df.sort_values('importance', ascending = False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec21842c-5c2a-44ab-bebb-8512dedfe391",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(feature_importance_df[['importance']], labels=feature_importance_df[['feature']], colors=colors, shadow=True)\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.title('Effect of various features on tip percentage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ed3669-efe1-4e64-a388-4b6e4e7b0b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_importances_idx = importance.importances_mean.argsort()\n",
    "importances = pd.DataFrame(\n",
    "    result.importances[sorted_importances_idx].T,\n",
    "    columns=X.columns[sorted_importances_idx],\n",
    ")\n",
    "ax = importances.plot.box(vert=False, whis=10)\n",
    "ax.set_title(\"Permutation Importances (test set)\")\n",
    "ax.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
    "ax.set_xlabel(\"Decrease in accuracy score\")\n",
    "ax.figure.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa86b9b-46b8-42b0-9bf8-266e0ea188d1",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f4d927-6248-4ebb-9623-eb261911a01a",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927792db-6fc7-472f-a0fb-cbca41b5d9b9",
   "metadata": {},
   "source": [
    "Stuff written so nicely..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd9bcc1-0c9b-45c3-b8df-b4240a7594eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea0cecd-1e71-494e-8874-d527b7c3259a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
